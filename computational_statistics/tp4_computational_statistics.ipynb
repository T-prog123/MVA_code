{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "de77eaeb",
   "metadata": {},
   "source": [
    "**student**: Titouan Le Breton"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d4a2c917",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba8fcf72",
   "metadata": {},
   "source": [
    "# Exercise 1.A"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26f17b76",
   "metadata": {},
   "source": [
    "### Question 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1aabf32",
   "metadata": {},
   "source": [
    "A gibbs sampler is a sampling one cordinate conditionaly on the others. Sometimes, you can't sample this conditional, so you need MH.\n",
    "\n",
    "It seems we select one o fthe indexes at random.\n",
    "\n",
    "\n",
    "Here, we use MH to sample tehe condtional distribution pi(x_i|x_-i)\n",
    "\n",
    "so the algirthm is: \n",
    "\n",
    "for step in n:\n",
    "    sample i form 1,2\n",
    "    update x_i with MH\n",
    "\n",
    "P_1 and P_2 sample the first and second coordinate respectively. However, they take as input z in R2.... which will have one of this coordinates unchanged\n",
    "\n",
    "we are in the case where pi(x_prop|y) / pi(x|y) = pi(x_prop, y) / pi(x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2925a34",
   "metadata": {},
   "source": [
    "### Question 2 and 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59d86901",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.15178705, 0.96078197, 0.8429807 , 0.77700862, 0.567476  ])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def pi(x,y , a=10):\n",
    "    store_var = -np.power(x,2) / a**2 - np.power(y,2) - 0.25*np.power(np.power(x,2)/a**2 - np.power(y,2) ,2)\n",
    "    return np.exp(store_var)\n",
    "\n",
    "x = np.random.randn(5)\n",
    "y = np.random.randn(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "46eae2fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_P1(x, y, sigma_1, pi):\n",
    "    x_prop = x + np.random.normal(0, sigma_1)\n",
    "    alpha = min(1, pi(x_prop, y) / pi(x, y))\n",
    "\n",
    "    if np.random.rand() < alpha:\n",
    "        return x_prop, y\n",
    "    else:\n",
    "        return x, y\n",
    "\n",
    "\n",
    "def sample_P2(x, y, sigma_2, pi):\n",
    "    y_prop = y + np.random.normal(0, sigma_2)\n",
    "    alpha = min(1, pi(x, y_prop) / pi(x, y))\n",
    "\n",
    "    if np.random.rand() < alpha:\n",
    "        return x, y_prop\n",
    "    else:\n",
    "        return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "7e07d83b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def MH_with_gibs(sigma_1, sigma_2, pi, N_steps, return_acceptance_ratio = False):\n",
    "    #just run the sampler N_steps times\n",
    "    x = np.random.randn()\n",
    "    y = np.random.randn()\n",
    "    count_x_accepted = 0\n",
    "    count_y_accepted = 0\n",
    "    x_list = [x]\n",
    "    y_list = [y]\n",
    "    for i in range(N_steps):\n",
    "        x_new,y = sample_P1(x, y, sigma_1, pi)\n",
    "        x_new,y_new = sample_P2(x_new, y, sigma_2, pi)\n",
    "\n",
    "        if x_new != x_new:\n",
    "            count_x_accepted += 1\n",
    "        if y_new != y:\n",
    "            count_y_accepted += 1\n",
    "            \n",
    "        x, y = x_new, y_new\n",
    "        x_list.append(x)\n",
    "        y_list.append(y)\n",
    "    if return_acceptance_ratio:\n",
    "        return x_list, y_list, count_x_accepted/ N_steps, count_y_accepted / N_steps\n",
    "    else:\n",
    "        return x_list, y_list\n",
    "        \n",
    "\n",
    "sigma_1 = 3\n",
    "sigma_2 = 3\n",
    "N_steps = 50\n",
    "\n",
    "x_MH, y_MH = MH_with_gibs(sigma_1, sigma_2, pi, N_steps, return_acceptance_ratio = False)     \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5ddabea5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "51"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca8f34cc",
   "metadata": {},
   "source": [
    "### Q4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fd6384b",
   "metadata": {},
   "source": [
    "We do not get good results. We move a lot on x, but not a lot on y. So we accept a lot on x but not on y (we get horiztional lines). It is an issue of variance: it is too small on the x (we accept to often) and to big on y (the proposition are too drasticall and we reject too often)\n",
    "\n",
    "Solution? make sigma_1 larger and sigma_2 smaller\n",
    "\n",
    "\n",
    "To check the quality of the markov chain, you can do an autocorrelation plot (you want it to go to 0 when the lag is large so you get indepndence)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8332c227",
   "metadata": {},
   "source": [
    "# Exercise 1.B"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6b8a9d8",
   "metadata": {},
   "source": [
    "The idea is to modify the variances to always have an acceptable acceptance rate (around 0.25%)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d79a37b",
   "metadata": {},
   "source": [
    "### Question 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4488e8f3",
   "metadata": {},
   "source": [
    "same as before, but after 50 steps we change the variance\n",
    "\n",
    "Note: in practice, we look at effective acceptance ratio (not the average alphas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "cbe43c7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_variance(sigma_1, sigma_2, x_acceptance_ratio, y_acceptance_ratio,sigma_j, golden_ratio):\n",
    "    if x_acceptance_ratio > golden_ratio:\n",
    "        sigma_1 -= sigma_j\n",
    "    else:\n",
    "        sigma_1 += sigma_j \n",
    "    \n",
    "    if y_acceptance_ratio > golden_ratio:\n",
    "        sigma_2 -= sigma_j\n",
    "    else:\n",
    "        sigma_2 += sigma_j \n",
    "    \n",
    "    return sigma_1, sigma_2\n",
    "\n",
    "\n",
    "def adaptive_MH_with_gibs(sigma_1, sigma_2, pi, N_batches):\n",
    "    x_list = []\n",
    "    y_list = []\n",
    "    N_steps = 50\n",
    "    golden_ratio = 0.234\n",
    "    for j in range(1,N_batches+1):\n",
    "        # do the sampling N_steps times\n",
    "        x, y, x_acceptance_ratio, y_acceptance_ratio = MH_with_gibs(sigma_1, sigma_2, pi, N_steps, return_acceptance_ratio = True)\n",
    "        x_list.append(x)\n",
    "        y_list.append(y)\n",
    "\n",
    "        # handle the modified vaiances to get a better acceptance ratio\n",
    "        sigma_j = min(0.05, j**(-0.5))\n",
    "        sigma_1, sigma_2 = update_variance(sigma_1, sigma_2, x_acceptance_ratio, y_acceptance_ratio,sigma_j, golden_ratio)\n",
    "    \n",
    "    return x_list, y_list\n",
    "\n",
    "N_batches = 5\n",
    "x_adaptive_MH, y_adaptive_MH = adaptive_MH_with_gibs(sigma_1, sigma_2, pi, N_batches)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0c74968",
   "metadata": {},
   "source": [
    "# Exercise 2.A"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b70ffd2",
   "metadata": {},
   "source": [
    "### Question 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "d51286ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "mu = np.array([\n",
    "    [2.18, 5.76], [8.67, 9.59], [4.24, 8.48], [8.41, 1.68], [3.93, 8.82], [3.25, 3.47], [1.70, 0.50], [4.59, 5.60], [6.91, 5.81], [6.87, 5.40],[5.41, 2.65],\n",
    "    [2.70, 7.88],[4.98, 3.70],[1.14, 2.39],[8.33, 9.50],[4.93, 1.50],[1.83, 0.09],[2.26, 0.31],[5.54, 6.86],[1.69, 8.11]\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "4f98b0d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 2)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mu.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "2ed81a4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 20)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sigma = 0.1\n",
    "w = 0.05\n",
    "\n",
    "x = np.array([1,-2])\n",
    "X = np.tile(x, (20, 1))\n",
    "\n",
    "\n",
    "exp_matrix = np.exp( (X - mu) @ (X - mu).T / (-2 * sigma**2))\n",
    "exp_matrix.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aff9e8f6",
   "metadata": {},
   "source": [
    "# Exercise 2.B"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93f4b12d",
   "metadata": {},
   "source": [
    "### Question 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23d58d25",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "comp_stat",
   "language": "python",
   "name": "comp_stat"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
